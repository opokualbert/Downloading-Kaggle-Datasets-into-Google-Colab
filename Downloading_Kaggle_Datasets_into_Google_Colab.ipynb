{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Downloading Kaggle Datasets into Google Colab.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "KN7mHLI7d-uE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this tutorial, I show how to download kaggle datasets into google colab. Kaggle has been and remains the  de factor platform to try your hands on data science projects. The platform has huge rich free datasets for machine learning projects.\n",
        "Another product from google, the company behind kaggle is colab, a platform suitable for training machine learning models and deep neural network free of charge without any installation requirement. One key thing that makes  colab a  game changer, especially for people who do not own GPU laptop is that users have the option to train their models with free GPU. Colab does not have the trove of datasets kaggle host on its platform therefore, it will be nice if you could access the datasets on kaggle from colab. There is in fact a kaggle API which we can use in colab but setting it up to work is not so easy. I would want to show how to use the API in a few simple steps.\n"
      ]
    },
    {
      "metadata": {
        "id": "DQ8S6vEgeTpq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Step 1\n",
        "Create a kaggle account if you do not have one already. Click on your user name, click on account and  scroll down to click on create new API token. This will download a file unto your PC. Note the location of the downloaded file."
      ]
    },
    {
      "metadata": {
        "id": "d5KwwFzVeuXQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Step 2\n",
        "Go to colab via this link: https://colab.research.google.com/notebooks/welcome.ipynb and under file, click on new python 3 notebook. In the first cell, type this code to install kaggle API and make a directory called kaggle.\n"
      ]
    },
    {
      "metadata": {
        "id": "0WMi_JQCeOAJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q kaggle\n",
        "!mkdir -p ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pztfupZ8fE7o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Step 3\n",
        "Type this code into the next cell and run to import the API key into colab"
      ]
    },
    {
      "metadata": {
        "id": "2gW9io83d7Wj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rgCojYb-fUvo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "In the next cell, copy the API  key to the kaggle directory we created."
      ]
    },
    {
      "metadata": {
        "id": "SOnXohYdfZs-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vKSIvcQufrbZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "The datasets should be available for us to use. Let us list the datasets with this code."
      ]
    },
    {
      "metadata": {
        "id": "Bc52_GCyfwIn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "558bdbf5-9410-4b46-9dfa-032d2c46a015"
      },
      "cell_type": "code",
      "source": [
        "!kaggle datasets list"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by otherusers on this system! To fix this, you can run'chmod 600 /root/.kaggle/kaggle.json'\n",
            "ref                                                             title                                                size  lastUpdated          downloadCount  \n",
            "--------------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  \n",
            "blastchar/telco-customer-churn                                  Telco Customer Churn                                172KB  2018-02-23 18:20:00           2557  \n",
            "heesoo37/120-years-of-olympic-history-athletes-and-results      120 years of Olympic history: athletes and results    5MB  2018-06-15 06:10:41           8304  \n",
            "neuromusic/avocado-prices                                       Avocado Prices                                      629KB  2018-06-06 05:28:35           3347  \n",
            "bigquery/patents                                                Google Patents Public Data                            2TB  2018-08-24 18:21:31              0  \n",
            "cityofLA/la-restaurant-market-health-data                       LA Restaurant & Market Health Data                   10MB  2018-08-17 20:29:28            963  \n",
            "open-powerlifting/powerlifting-database                         Powerlifting Database                                 9MB  2018-02-02 16:42:51           2358  \n",
            "meganrisdal/la-county-restaurant-inspections-and-violations     LA County Restaurant Inspections and Violations      19MB  2018-04-19 17:33:03            673  \n",
            "mathan/fifa-2018-match-statistics                               Predict FIFA 2018 Man of the Match                    4KB  2018-07-18 08:29:22           4499  \n",
            "decide-soluciones/air-quality-madrid                            Air Quality in Madrid (2001-2018)                   151MB  2018-06-18 13:18:22           2113  \n",
            "city-of-seattle/seattle-trade-permits                           Seattle Trade Permits                                13MB  2018-07-24 02:07:32            228  \n",
            "kevinarvai/clinvar-conflicting                                  Genetic Variant Classifications                       3MB  2018-04-22 19:16:07            887  \n",
            "datafiniti/fast-food-restaurants                                Fast Food Restaurants Across America                663KB  2018-04-10 18:35:54           1841  \n",
            "marklvl/bike-sharing-dataset                                    Bike Sharing in Washington D.C. Dataset             273KB  2018-05-28 11:31:09            931  \n",
            "new-york-city/ny-daily-inmates-in-custody                       NY Daily Inmates In Custody                         319KB  2018-09-03 07:15:46            497  \n",
            "lucidlenn/sloan-digital-sky-survey                              Sloan Digital Sky Survey RD14                       604KB  2018-03-09 11:03:45            428  \n",
            "passnyc/data-science-for-good                                   PASSNYC: Data Science for Good Challenge            164KB  2018-06-26 17:36:48           6100  \n",
            "4quant/depth-generation-lightfield-imaging                      Computational Imaging                               350MB  2018-07-10 16:58:22            280  \n",
            "mirichoi0218/insurance                                           Medical Cost Personal Datasets                      16KB  2018-02-21 00:15:14           5210  \n",
            "fernandol/countries-of-the-world                                Countries of the World                               13KB  2018-04-26 08:16:27           3733  \n",
            "tadhgfitzgerald/fifa-international-soccer-mens-ranking-1993now  FIFA Soccer Rankings                                693KB  2018-06-08 11:15:09           3486  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VZLlrQUlf5lW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Step 4\n",
        "We can download files now by using this sample code. In this case the US consumer finance complaints was downloaded."
      ]
    },
    {
      "metadata": {
        "id": "MLKb6AV_f73P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ce3727f2-3ce0-4ac4-846b-5c6644824bce"
      },
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d cfpb/us-consumer-finance-complaints\n",
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by otherusers on this system! To fix this, you can run'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading us-consumer-finance-complaints.zip to /content\n",
            " 98%|█████████████████████████████████████▍| 89.0M/90.5M [00:02<00:00, 40.9MB/s]\n",
            "100%|██████████████████████████████████████| 90.5M/90.5M [00:02<00:00, 38.5MB/s]\n",
            "kaggle.json  sample_data  us-consumer-finance-complaints.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c8VEznzPgRV8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Step 5\n",
        "We use pandas to read the data we have downloaded by unzipping the file first. This line of code works in most situations. "
      ]
    },
    {
      "metadata": {
        "id": "AU9_5j0rgC6s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "outputId": "e4e53659-a566-429d-df2c-20acfa10c8e0"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data2 = pd.read_csv('/content/us-consumer-finance-complaints.zip', compression='zip', header=0, sep=',', quotechar='\"')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-291f40351b47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/us-consumer-finance-complaints.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquotechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: ('Multiple files found in compressed zip file %s', \"['consumer_complaints.csv', 'database.sqlite']\")"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "1Ny5WCBVgkzk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It did not work here because the zipped file also contains a sqlite database. I will use a different method below to extract only the CSV."
      ]
    },
    {
      "metadata": {
        "id": "MAdd4U0Og0Ea",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "93df77af-f7c8-49ab-ceab-05c36e89c526"
      },
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "zip_file = ZipFile('/content/us-consumer-finance-complaints.zip')\n",
        "fields= ['product','consumer_complaint_narrative'] \n",
        "data=pd.read_csv(zip_file.open('consumer_complaints.csv'), usecols=fields)\n",
        "data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product</th>\n",
              "      <th>consumer_complaint_narrative</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mortgage</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mortgage</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Credit reporting</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Student loan</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Debt collection</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            product consumer_complaint_narrative\n",
              "0          Mortgage                          NaN\n",
              "1          Mortgage                          NaN\n",
              "2  Credit reporting                          NaN\n",
              "3      Student loan                          NaN\n",
              "4   Debt collection                          NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "mrku3E8ig1e9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}